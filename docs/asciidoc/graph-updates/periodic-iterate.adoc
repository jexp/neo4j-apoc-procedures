[[commit-batching]]
== Periodic Iterate

ifdef::backend-html5[]
++++
<iframe width="560" height="315" src="https://www.youtube.com/embed/t1Nr5C5TAYs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
++++
endif::[]

The `apoc.periodic.iterate` procedure is helpful when you need to handle large amounts of data for import, refactoring, and other cases that require large transactions.
It provides a way to batch the data by dividing the workload into two parts:

a data-driven statement:: This defines how you select what data needs handled.
You can provide a Cypher statement to select from existing graph data, read external data from a file or API, or retrieve data from another datastore.

an operation statement:: This defines what you want done to the selected data.
You can do things like execute Cypher for updating or creating/deleting the data or run other procedures to manipulate and transform values before loading.

The data-driven statement is provided as the *first*, outer statement that results in a stream of values to be processed.
The operations statement is provided as the *second*, inner statement to process *one* element at a time or (with `iterateList:true`) a batch at a time.
The results of the outer statement are passed to the inner statement as parameters, so they are automatically made available with their names.

.configuration options
[options=header]
|===
| param | default | description
| batchSize | 10000 | run the specified number of inner statements in a single tx - params: {_count, _batch}
| parallel | false | run inner statements in parallel (note that statements might deadlock if conflicting)
| retries | 0 | if the inner statement fails with an error, sleep 100ms and retry until retries-count is reached - param {_retry}
| iterateList | true | execute inner statements once per batchSize (whole batchSize list is passed in as parameter {_batch})
| params | {} | externally pass in map of params
| concurrency | 50 | number of concurrent tasks are generated when using `parallel:true`
| failedParams | -1 | if set to a non-negative value, each failed batch up to `failedParams` parameter sets are returned in `yield failedParams`.
|===

.Examples
So, if you were to add an `:Actor` label to several million `:Person` nodes, you could run the following code:

[source,cypher]
----
CALL apoc.periodic.iterate(
  "MATCH (p:Person) WHERE (p)-[:ACTED_IN]->() RETURN p",
  "SET p:Actor",
  {batchSize:10000, parallel:true})
----

Let's break down the parameters passed to the procedure:

* Our first Cypher statement selects all the `Person` nodes with an `ACTED_IN` relationship to another node and returns those persons.
This is the data-driven portion where we select the data that we want to change.

* Our second Cypher statement sets the `:Actor` label on each of our `Person` nodes we selected.
This is the operations portion where we apply the change to the data from our first statement.

* And finally, we specify any configurations we want the procedure to use.
We have defined a `batchSize` of 10,000 and to run the statements in parallel.

Executing this procedure would take all of our `Person` nodes gathered in the first Cypher statement and update each of them with the second Cypher statement.
It divides the work into batches - taking 10,000 `Person` nodes from the stream and updating them in a single transaction.
If we have 30,000 `Person` nodes in our graph with an `ACTED_IN` relationship, then it would break this down into 3 batches.

Finally, it runs those in parallel, as updating node labels or properties do not conflict.

[NOTE]
====
For more complex operations like updating or removing relationships, either *do not use parallel: true* OR make sure that you batch the work in a way that each subgraph of data is updated in one operation, such as by transferring the root objects.
If you attempt complex operations, also enable retrying failed operations, e.g. with `retries:3`.
====

Now let us look at a more complex example.

[source,cypher]
----
CALL apoc.periodic.iterate(
  "MATCH (o:Order) WHERE o.date > '2016-10-13' RETURN o",
  "MATCH (o)-[:HAS_ITEM]->(i) WITH o, sum(i.value) as value SET o.value = value",
  {batchSize:100, parallel:true})
----

Let's break down the parameters passed to the procedure:

* Our first Cypher statement selects all the `Order` nodes that have an order date greater than `October 13, 2016` (first Cypher statement).
* Out second Cypher statement takes those groups and finds the nodes that have a `HAS_ITEM` relationship to other nodes, then sums up the value of those items and sets that sum as a property (`o.value`) for the total order value.
* Our configuration will batch those nodes into groups of 100 (`batchSize:100`) and run the batches in parallel for the second statement to process.