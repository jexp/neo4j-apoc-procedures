[[export-cypher]]
== Export to Cypher Script

[abstract]
--
This section describes procedures that can be used to export data in Cypher format.
--

====
If you are experimenting with imports that are failing you can add the `--debug` command line parameter, to see which statement was executed last and cause the failure.

Also check the memory configuration of your Neo4j instance, you might want to up the HEAP to *2–4GB* with the `dbms.memory.heap.max_size=2G` setting in `neo4j.conf`.

And provide more memory to cypher-shell itself by prefixing the command with: `JAVA_OPTS=-Xmx4G bin/cypher-shell …`
====

Make sure to set the config options in your `neo4j.conf`

.neo4j.conf
----
apoc.export.file.enabled=true
apoc.import.file.enabled=true
----

Data is exported as Cypher statements to the given file.

It is possible to choose between three export formats (`cypher-shell` is the default value):

* `cypher-shell`: for Cypher shell
* `neo4j-shell`: for Neo4j Shell and partly `apoc.cypher.runFile`
* `plain`: doesn't output begin / commit / await just plain Cypher

You can also use the Optimizations like: `useOptimizations: {config}`
Config could have this params:

* `unwindBatchSize`:  (default 100)
* `type`: possible values ('NONE', 'UNWIND_BATCH', 'UNWIND_BATCH_PARAMS') (default 'UNWIND_BATCH')

With `NONE` it will export the file with `CREATE` statement;

With 'UNWIND_BATCH` it will export the file by batching the entities with the `UNWIND` method as explained in this
https://medium.com/neo4j/5-tips-tricks-for-fast-batched-updates-of-graph-structures-with-neo4j-and-cypher-73c7f693c8cc[article].

To change the export format, you have to set it on the config params like `{format : "cypher-shell"}`.

By default the format is `neo4j-shell`.

If you want to export to separate files, e.g. to later use the `apoc.cypher.runFiles/runSchemaFiles` procedures, you can add `separateFiles:true`.

It is possible to choose between four cypher update operation types:
To change the cypher update operation, you have to set it on the config params like `{cypherFormat: "updateAll"}`

* `create`: all CREATE
* `updateAll`: MERGE instead of CREATE
* `addStructure`: MATCH for nodes + MERGE for rels
* `updateStructure`: MERGE + MATCH for nodes and rels

In case of `cypher-shell` export format you can also set the timeout of `db.awaitIndexes` with the `awaitIndexes`
configuration param.

Format and cypherFormat can be used both in the same query giving you complete control over the exact export format:

[source,cypher]
----
call apoc.export.cypher.query(
"MATCH (p1:Person)-[r:KNOWS]->(p2:Person) RETURN p1,r,p2",
"/tmp/friendships.cypher", 
{format:'plain',cypherFormat:'updateStructure'})`
----


// tag::export.cypher[]
`YIELD file, source, format, nodes, relationships, properties, time`
[separator=¦,opts=header,cols="1,1m,1m,5"]
|===
include::../../../build/generated-documentation/apoc.export.cypher.csv[]
|===
// end::export.cypher[]

[NOTE]
The labels exported are ordered alphabetically.
The output of `labels()` function is not sorted, use it in combination with `apoc.coll.sort()`.

=== Roundtrip Example

You can use this roundtrip example e.g. on the `:play movies` movie graph.

Make sure to set the config options in your `neo4j.conf`

.neo4j.conf
----
apoc.export.file.enabled=true
apoc.import.file.enabled=true
----

Export the data in plain format and multiple files:

[source,cypher]
----
call apoc.export.cypher.query("match (n)-[r]->(n2) return * limit 100",
 "/tmp/mysubset.cypher",
 {format:'plain',separateFiles:true});
----

This should result in 4 files in your directory.

[source,shell]
----
ls -1 /tmp/mysubset.*
/tmp/mysubset.cleanup.cypher
/tmp/mysubset.nodes.cypher
/tmp/mysubset.relationships.cypher
/tmp/mysubset.schema.cypher
----

Import the data in 4 steps, first the schema, then nodes and relationships, then cleanup.

---
call apoc.cypher.runSchemaFile('/tmp/mysubset.schema.cypher');
call apoc.cypher.runFiles(['/tmp/mysubset.nodes.cypher','/tmp/mysubset.relationships.cypher']);

// remove temporary node properties
call apoc.cypher.runFile('/tmp/mysubset.cleanup.cypher');
// drop import specific constraint
call apoc.cypher.runSchemaFile('/tmp/mysubset.cleanup.cypher');
---

The `run*` procedures have some optional config:

* `{statistics:true/false}` to output a row of update-stats per statement, default is true
* `{timeout:1 or 10}` for how long the stream waits for new data, default is 10

=== Stream back Exported Cypher Script as columns

If you leave off the file-name as `null` the export will instead be streamed back.

In general there will be a `cypherStatements` column with the script.

If you use multi-file-splitting as configuration parameter, there will be extra columns with content for

* nodeStatements
* relationshipStatements
* cleanupStatements
* schemaStatements

If you also specify the `streamStatements:true` then each batch (by `batchSize` which defaults to 10k) of statements will be returned as a row.
So you can use your client to reconstruct the cypher script.

.Simple Example for Streaming
[source,cypher]
----
echo "
CALL apoc.export.cypher.all(null,{streamStatements:true,batchSize:100}) YIELD cypherStatements RETURN cypherStatements;
" | ./bin/cypher-shell --non-interactive --format plain
----

=== Examples

.exportAll (neo4j-shell format)

==== Old method:

Without the optimizations

[source,cypher]
----
CALL apoc.export.cypher.all({fileName},{config})
----
Result:
[source,cypher]
----
begin
CREATE (:Foo:`UNIQUE IMPORT LABEL` {name:"foo", `UNIQUE IMPORT ID`:0});
CREATE (:Bar {name:"bar", age:42});
CREATE (:Bar:`UNIQUE IMPORT LABEL` {age:12, `UNIQUE IMPORT ID`:2});
commit
begin
CREATE INDEX ON :Foo(name);
CREATE CONSTRAINT ON (node:Bar) ASSERT node.name IS UNIQUE;
CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT node.`UNIQUE IMPORT ID` IS UNIQUE;
commit
schema await
begin
MATCH (n1:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`:0}), (n2:Bar{name:"bar"}) CREATE (n1)-[:KNOWS]->(n2);
commit
begin
MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;
commit
begin
DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT node.`UNIQUE IMPORT ID` IS UNIQUE;
commit
----
.exportSchema (neo4j-shell format)
[source,cypher]
----
CALL apoc.export.cypher.schema({fileName},{config})
----
Result:
[source,cypher]
----
begin
CREATE INDEX ON :Foo(name);
CREATE CONSTRAINT ON (node:Bar) ASSERT node.name IS UNIQUE;
commit
schema await
----

==== New method:

With the optimizations

[source,cypher]
----
CALL apoc.export.cypher.all({fileName},{config})
----
Result:
[source,cypher]
----
BEGIN
CREATE INDEX ON :Bar(first_name,last_name);
CREATE INDEX ON :Foo(name);
CREATE CONSTRAINT ON (node:Bar) ASSERT node.name IS UNIQUE;
CREATE CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT node.`UNIQUE IMPORT ID` IS UNIQUE;
COMMIT
SCHEMA AWAIT
BEGIN
UNWIND [{_id:3, properties:{age:12}}] as row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar;
UNWIND [{_id:2, properties:{age:12}}] as row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Bar:Person;
UNWIND [{_id:0, properties:{born:date('2018-10-31'), name:"foo"}}, {_id:4, properties:{born:date('2017-09-29'), name:"foo2"}}] as row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties SET n:Foo;
UNWIND [{name:"bar", properties:{age:42}}, {name:"bar2", properties:{age:44}}] as row
CREATE (n:Bar{name: row.name}) SET n += row.properties;
UNWIND [{_id:6, properties:{age:99}}] as row
CREATE (n:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row._id}) SET n += row.properties;
COMMIT
BEGIN
UNWIND [{start: {_id:0}, end: {name:"bar"}, properties:{since:2016}}, {start: {_id:4}, end: {name:"bar2"}, properties:{since:2015}}] as row
MATCH (start:`UNIQUE IMPORT LABEL`{`UNIQUE IMPORT ID`: row.start._id})
MATCH (end:Bar{name: row.end.name})
CREATE (start)-[r:KNOWS]->(end) SET r += row.properties;
COMMIT
BEGIN
MATCH (n:`UNIQUE IMPORT LABEL`)  WITH n LIMIT 20000 REMOVE n:`UNIQUE IMPORT LABEL` REMOVE n.`UNIQUE IMPORT ID`;
COMMIT
BEGIN
DROP CONSTRAINT ON (node:`UNIQUE IMPORT LABEL`) ASSERT (node.`UNIQUE IMPORT ID`) IS UNIQUE;
COMMIT
----
